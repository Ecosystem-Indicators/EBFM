---
title: "Lenfest model indicators - calculation for EwE models"
author: "Linda Thomas, Camilla Novaglio, Beth Fulton & Javier Porobic"
date: "19/07/2021"
output: html_document
editor_options: 
chunk_output_type: console
---

# Indicator calculation for EwE models
This document provides the scripts to run the Priority 1 indicators for EwE models.
These are calculated using the model output files. Some additional information may be required to be collated.

# Clean up before you start
```{r}

rm(list=ls())

```

# load libraries 
Below are the libraries to be loaded - first it runs the function that will check
# if the library is installed or not and if not then installs it so ready for usechecks if installed or not and if not then installs
```{r}
install_load <- function (this_package)  {   

   package <- c(this_package)
   if(package %in% rownames(installed.packages()))
        do.call('library', list(package))

    # if package is not installed locally, download, then load
    else {
        install.packages(package)
         do.call("library", list(package))
    }
}

### load/install libraries ###
# Data handling and table reshaping
install_load("tidyverse")
install_load("reshape2")
install_load("devtools")
install_load("MASS")
install_load("dplyr")
#install_load("Tool.R")
# Plotting
install_load("ggplot2")
install_load("RColorBrewer")
#install_load("ggbiplot")
install_load("plot3D")
install_load("plotly")
# PCA and Clustering
install_load("factoextra")
install_load("FactoMineR")
install_load("corrplot")
install_load("ape")
install_load("plot3D")
install_load("heatmaply")
install_load("data.table")
# Timeserise analysis
install_load("zoo")
#Other
install_load("Rcpp")
install_load("inline")
install_load("vegan")
install_load("patchwork")
install_load("cowplot")
install_load("ggpubr")
install_load("matrixStats")
install_load("drc")
install_load("viridis") 
install_load("gridExtra")
install_load("cowplot")
#Network related
install_load("data.table")
install_load("magrittr")
install_load("qgraph")
install_load("visNetwork")
install_load("intergraph")
install_load("tidygraph")
install_load("network")
install_load("igraph")



```

# Data collection  
Please set the working directory to where the model output files are.  

Additional information to be provided by the modeller:  
* A list of species used in your model in csv format (e.g ID, Group). This can be taken from the model parameters file used to set up the model.  
* L inf for each species in the model. This is taken from the model parameter file. Calculate the mean L infinity for the species group.
* size categories for each species in csv format (e.g. species_id, Group, size). The information is taken from the model parameters file. Categorise each group into L, S or split depending on total length (small = <30cm, large = >50cm, SPLIT = 30-50cm).

```{r}

# Palettes to use
tscolor <- "red4"
aggtscolor <-"deepskyblue4"
aggtscolor2 <- "deepskyblue"
textsize <- 16
linesize <- 3
nPanel <- 12
header_row_ID <- 10   # this needs to change between EwE versions and if use observation csv
chl_from_file <- 0
bo_in_same_file <- 0
bo_conservative <- 1
bo_yr_row <- 0 # Set to 0 if you want the final row of the file
bo_header_row_ID <- 14   # this needs to change between EwE versions and if use observation csv

# Area of model in km2 (whole of SESSF = 3700000), EBS smaller
area_model <- 36500

# Define the relevant directories - all these paths (including the output directories) must already exist
mainDir <- "/Users/ful083/Work/Lenfest_EBFM/case_studies/SE_Aust/EwE_model_output"
InputsubDir <- "EBS output files/ecosim_Climate control with fishing"
OutsubDirStep1 <- "Lenfest_output"
OutsubDirStep2 <- "EBS - ecosim_Climate control with fishing"
BosubDir <- "EBS output files/EBS_2021_version/NoFishing"

```

# Load the data
```{r}
# set working directory - change to where your model output files are.
setwd(mainDir)
OutsubDirStep3 <- paste(OutsubDirStep1,"/",OutsubDirStep2,sep="")
OutDir <- paste(mainDir,"/",OutsubDirStep3,sep="")
skip_this  <- header_row_ID - 1

# Create output directory if required
ifelse(!dir.exists(file.path(mainDir, OutsubDirStep1)), dir.create(file.path(mainDir, OutsubDirStep1)), FALSE)
ifelse(!dir.exists(file.path(mainDir, OutsubDirStep2)), dir.create(file.path(mainDir, OutsubDirStep2)), FALSE)

# read in EwE data
# find model start year from an output file
BioFile <- paste(mainDir,"/",InputsubDir,"/","biomass_annual.csv",sep="")
d <- read.csv(BioFile, header = FALSE)
s_year = d[c(1:7), ];               # this reads the first 7 rows of the header to give the start year of the model.

# catch data
CatchFile <- paste(mainDir,"/",InputsubDir,"/","catch_annual.csv",sep="")
catch <- read.csv(CatchFile, header = T, skip = skip_this, check.names = FALSE) # because csv file has headers - will need to skip the first 9 rows; check names makes sure an X isn't added before the number for the species
names(catch)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# aggregate landings data
LandFile <- paste(mainDir,"/",InputsubDir,"/","landings_annual.csv",sep="")
landings <- read.csv(LandFile, header = T, skip = skip_this, check.names = FALSE) # because csv file has headers - will need to skip the first 9 rows; check names makes sure an X isn't added before the number for the species
names(landings)[1] <- 'Year'   # changes the name of the first column to year instead of year//group
names(landings)[3] <- 'species_id'   # changes the name of the first column to year instead of year//group

# biomass data
biomass <- read.csv(BioFile, header = T, skip = skip_this, check.names = FALSE)
names(biomass)[1] <- 'Year'

# total catch and landings data per fleet
RemFile <- paste(mainDir,"/",InputsubDir,"/","catch-fleet-group_annual.csv",sep="")
removals_fleet <- read.csv(RemFile, header = T, skip = skip_this, check.names = FALSE)
names(removals_fleet)[1] <- 'Year'
LFFile <- paste(mainDir,"/",InputsubDir,"/","landings_annual.csv",sep="")
landings_fleet <- read.csv(LFFile, header = T, skip = skip_this, check.names = FALSE)
names(landings_fleet)[1] <- 'Year'

# species id - put names
id <- read.csv("Species_ID.csv") # You will need to put in the name of your species list csv file here
nSPName <- length(unique(id$Group))
SpeciesNames <- id$Group

# fleet id - put names
idf <- read.csv("Fleet_ID.csv") # You will need to put in the name of your species list csv file here
nFName <- length(unique(idf$Fleet.name))
FleetNames <- idf$Fleet.name

# mortality data
MortFile <- paste(mainDir,"/",InputsubDir,"/","mort-fleet-group_annual.csv",sep="")
mortality_fleet <- read.csv(MortFile, header = T, skip = skip_this, check.names = FALSE)
names(mortality_fleet)[1] <- 'Year'
MortFile <- paste(mainDir,"/",InputsubDir,"/","mortality_annual.csv",sep="")
mortality <- read.csv(MortFile, header = T, skip = skip_this, check.names = FALSE)
names(mortality)[1] <- 'Year'

# trophic level data
TLFile <- paste(mainDir,"/",InputsubDir,"/","tl_annual.csv",sep="")
tl_annual <- read.csv(TLFile, header = T, skip = skip_this, check.names = FALSE)
names(tl_annual)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# weight data
WeightFile <- paste(mainDir,"/",InputsubDir,"/","weight_annual.csv",sep="")
weight_annual <- read.csv(WeightFile, header = T, skip = skip_this, check.names = FALSE)
names(weight_annual)[1] <- 'Year'   # changes the name of the first column to year instead of year//group

# chl file if present
if (chl_from_file > 0) {
  ChlFile <- paste(mainDir,"/",InputsubDir,"/","chl.csv",sep="")   # Assumes a format of Year chl
  dfChl <- read.csv(ChlFile, header = T, check.names = FALSE)
  
  # make sure has columns Year and Chl
}

# convert data into a data frame and pivot tables to tidy
bio <- as.data.frame(biomass) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "biomass_tonnes")
bio$biomass_tonnes <- area_model * bio$biomass_tonnes

cat <- as.data.frame(catch) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "catch_tonnes")
cat$catch_tonnes <- area_model * cat$catch_tonnes

aggland <- landings %>%
  group_by(Year, species_id) %>%
  dplyr::summarise(landings_tonnes = sum(value))
aggland$landings_tonnes <- area_model * aggland$landings_tonnes
aggland$species_id <- as.character(aggland$species_id)

tl <- as.data.frame(tl_annual) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "trophic_level")

land <- as.data.frame(landings_fleet) %>% 
  dplyr::rename(species_id = group) %>% # rename group to species_id
  dplyr::rename(fleet_landing_tonnes = value) %>% # rename value to landing_tonnes
  mutate(species_id = as.character(species_id)) %>% 
  unique()
land$fleet_landing_tonnes <- area_model * land$fleet_landing_tonnes

removals <- as.data.frame(removals_fleet) %>% 
  dplyr::rename(species_id = group) %>% # rename group to species_id
  dplyr::rename(fleet_removals_tonnes = value) %>% # rename value to landing_tonnes
  mutate(species_id = as.character(species_id)) %>% 
  unique()
removals$fleet_removals_tonnes <- area_model * removals$fleet_removals_tonnes

# add in species names to the data frame
## change the COL_ID to species_id so can join
id2 <- id %>% 
  dplyr::rename(species_id = ID) %>%  # specify that the dplyr rename is the function you want & rename ID to species_id
#    select(-COL_ID) %>% # removes the COL_ID column
  mutate(species_id = as.character(species_id)) %>% # change to character so same as other data frame
  unique() # make sure only unique values are used.

# merge the catch and biomass into one data frame
df1tmp <- full_join(bio, cat) # have two columns the same so they will automatically join on these
df1 <- full_join(df1tmp, aggland)
df1[is.na(df1)] <- 0
df <- full_join(df1, id2) # data frame with biomass, catch and species names

# df3 <- full_join(df, land) %>% # data frame with biomass, catch and species names & landings
#  select(Year, species_id, Group, fleet, biomass_tonnes, catch_tonnes, fleet_landing_tonnes) # reorder the columns so they are easier to read

# New df3 which has landings and total catch per fleet in one file
df3tmp <- full_join(land, removals)

# Join landings and species names
df3tmpA <- full_join(df3tmp, id2) 
df3 <- merge(df3tmpA, idf, by.x = "fleet", by.y = "ID") 

# add species names to trophic level data
tl_species <- full_join(tl, id2)

# Get reference values
# Depending on the value of bo_conservative set Bo
# bo_in_same_file = 1 then take Bs from row bo_yr_row
# bo_in_same_file = 0 and bo_conservative = 0 then take Bs from the Bo file as dicatted by bo_yr_row
# bo_in_same_file = 0 and bo_conservative = 1 then take max(first row of biofile, row of Bo file)

if(bo_in_same_file < 1){
  # Load Bo and Mo from files
  bo_skip_this <- bo_header_row_ID - 1
  BoBioFile <- paste(mainDir,"/",BosubDir,"/","biomass_annual.csv",sep="")
  BoBio <- read.csv(BoBioFile, header = T, skip = bo_skip_this, check.names = FALSE)
  MoMortFile <- paste(mainDir,"/",BosubDir,"/","mortality_annual.csv",sep="")
  MoMort <- read.csv(MoMortFile, header = T, skip = bo_skip_this, check.names = FALSE)
  names(BoBio)[1] <- 'Year'
  names(MoMort)[1] <- 'Year' 
  if(bo_yr_row < 1) {
    bo_yr_row <- length(BoBio[,1])
    RefB <- BoBio[bo_yr_row,]
    RefM <- MoMort[bo_yr_row,]
    
  } else {
    RefB <- BoBio[bo_yr_row,]
    RefM <- MoMort[bo_yr_row,]
  }
  
  if(bo_conservative > 0) {
    altB1 <- as.data.frame(RefB) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    altBtmp <- biomass[1,]
    altB2 <- as.data.frame(altBtmp) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    altB1$Year <- RefM[1,1]
    altB2$Year <- RefM[1,1]
    dftmp <- merge(altB1, altB2, by=c("Year","species_id"))
    dftmp$RefB <- ifelse(dftmp$RefB.x > dftmp$RefB.y, dftmp$RefB.x, dftmp$RefB.y)
    dfRefB <- dftmp
    dfRefB <- subset (dfRefB, select = -c(Year, RefB.x, RefB.y))
  } else {
    dfRefB <- as.data.frame(RefB) %>% 
      pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
    dfRefB <- subset (dfRefB, select = -c(Year))
  }
  dfRefM <- as.data.frame(RefM) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefM")
  dfRefM <- subset (dfRefM, select = -c(Year))
  
} else {
  # Assumes has sensible reference year rown number
  RefB <- biomass[bo_yr_row,]
  RefM <- mortality[bo_yr_row,]
  
  dfRefB <- as.data.frame(RefB) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefB")
  dfRefB <- subset (dfRefB, select = -c(Year))
  dfRefM <- as.data.frame(RefM) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "RefM")
  dfRefM <- subset (dfRefM, select = -c(Year))

}
dfRef <- merge(dfRefM, dfRefB, by=c("species_id")) # Intentional reuse
dfRef$RefBo <- area_model * dfRef$RefB

```

# Fishery Indicators

## Biomass time series - EwE
```{r}
# written by Beth

# data to use
#head(df)
# Species biomass time series - so cna check rest makes sense
this_nSPName <-length(unique(df$Group))
this_SpeciesNames <- unique(df$Group)
dftmp <- merge(df, dfRef, by = c("species_id"))
  
# plot out catch for each species for each fleet 
nLoop <- ceiling (this_nSPName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (i in 1:nLoop) {
  check_name <- this_SpeciesNames[counter1:counter2]  
  extractdf <- dplyr::filter(dftmp, Group %in% check_name)
  outfilepng <- paste("biomass",i,"-page",i,".png",sep="")
  p <- ggplot(extractdf, aes(x = Year, y = biomass_tonnes)) +
    geom_line(color = tscolor, size = 1.2) +
    geom_line(aes(x = Year, y = RefBo), color = "black", size = 0.8, linetype="twodash") +
    theme(legend.position = "none") +
    expand_limits(y=0) +
    labs(
        x = "Year",
        y = "Biomass (tonnes)") +
    facet_wrap(~ Group, scales = 'free') +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

  ggsave(filename = outfilepng, plot = p, path = OutDir)
  counter1 <- counter1 + nPanel
  counter2 <- counter2 + nPanel
}

```

## Catch time series (per species per gear) - commercial, recreational, artisinal - EwE  
```{r}
# written by Beth

# data to use
head(df3)

# subset out data by fleet
# to see how many fleets
df4 <- na.omit(df3)
tmp <- unique(df4[c("fleet")])
nFleet <- max(tmp[,1])

for (i in 1:nFleet) {
  
  txttitle <- paste("Catch time series by species by fleet ",i,sep="")
  catch_fi <- df3 %>% dplyr::filter(fleet == i)
  this_fleet <-idf[i,2]
  this_nSPName <-length(unique(catch_fi$Group))
  this_SpeciesNames <- unique(catch_fi$Group)
  
  # plot out catch for each species for each fleet 
  nLoop <- ceiling (this_nSPName / nPanel)
  counter1 <- 1
  counter2 <- nPanel
  counter3 <- 1
  for (iLoop in 1:nLoop) {
    
    check_name <- this_SpeciesNames[counter1:counter2]  
    extractC <- dplyr::filter(catch_fi, Group %in% check_name)
    lenC <- dim(extractC)
    l1 <- lenC[1]
    if(l1 > 0) {
      outfilepng <- paste("catch-fleet",i,"-page",counter3,".png",sep="")
      catch_pi <- ggplot(extractC, aes(x = Year, y = fleet_landing_tonnes)) +
        geom_line(color = tscolor, size = 1.2) +
        theme(legend.position = "none") +
        expand_limits(y=0) +
        labs(
          title = txttitle,
          subtitle = this_fleet,
          x = "Year",
          y = "Amount of catch (tonnes)") +
        facet_wrap(~ Group, scales = 'free') +
        theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

      # save out plots
      #ggsave(file=outfilepng)
      ggsave(filename = outfilepng, plot = catch_pi, path = OutDir)
      counter3 <- counter3 + 1
    }
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
  }
  
  
}

```

## Catch species composition - fishery
PCA run on the output file (catch_fleet_group_annual)
```{r}
# written by Beth

# data to use
#head(df3)
#head(df)

# Recast so the species are the columns - starting by getting catch per year from old df3
#CdataS <- df3 %>%
#  group_by(Year, Group) %>%
#  dplyr::summarise(TotalYield = mean(catch_tonnes))
# Now just take it straight from df
CdataS <- df

# Replace spaces in names with "_"
CdataS$Group <- gsub("\\(", "", CdataS$Group)
CdataS$Group <- gsub("\\/", "", CdataS$Group)
CdataS$Group <- gsub(")", "", CdataS$Group)
CdataS$Group <- gsub("&", "", CdataS$Group)
CdataS$Group <- gsub("-", "", CdataS$Group)
CdataS$Group <- gsub(" ", "", CdataS$Group)
#CdataS$Group <- gsub("  ", " ", CdataS$Group)
#CdataS$Group <- gsub(" ", "_", CdataS$Group)
#SP_as_colA <- dcast(CdataS, Year ~ Group, value.var = "TotalYield")

SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "catch_tonnes")

# Replace NA with zeros
SP_as_colA[is.na(SP_as_colA)] <- 0

# Strip out columns of all zeros
SP_as_col <- SP_as_colA[, colSums(SP_as_colA != 0) > 0]

# Get the column headers
dimC <- dim(SP_as_col)
pc.f <- formula(paste("~", paste(names(SP_as_col)[2:dimC[2]], collapse = "+")))

# PCA calculations - using spectral decomposition approach via the princomp approach
pl.pca <- princomp(pc.f, cor=TRUE, data=SP_as_col)

# Put on row named
row.names(pl.pca$scores) <- SP_as_col$Year

# Plot results - look to see number of PCA axes to retain
OutFilename <- paste(OutDir,"/PCA_VarExplained.png",sep="")
png(OutFilename, 1200, 800)
plot(pl.pca, type="lines")
dev.off()
  
# Plot biplot
outBiplot <- paste(OutDir,"/PCA_Biplot_Thru_Time.png",sep="")   
dfPCA <- data.frame(comp1=pl.pca$scores[,1],
                 comp2=pl.pca$scores[,2])
ggplot(data = dfPCA, aes(x=comp1, y=comp2, group=1)) +
    geom_point(size=5, aes(colour=rownames(pl.pca$scores))) +
    geom_path(size = 0.2) +
    geom_text(label=rownames(pl.pca$scores)) + 
    theme(legend.position="none")
ggsave(file=outBiplot)

## Use prcomp() instead - this uses singular value decomposition (can handle case when there is more variables than observations)
res.pca <- prcomp(SP_as_col, scale = TRUE)

# Visualize eigenvalues (scree plot). Show the percentage of variances explained by each principal component.
OutFilename <- paste(OutDir,"/PCA_Scree_plot.png",sep="")
png(OutFilename, 1200, 800)
fviz_eig(res.pca)
dev.off()

#Graph of individuals. Individuals with a similar profile are grouped together.
fviz_pca_ind(res.pca,
             col.ind = "contrib", # Color by congtribution
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             #label=SP_as_col$Year
) +
  labs(title ="PCA", x = "PC1", y = "PC2")

# Graph of variables
PCA_color_gradient <- c("#36648B", "#FFA500", "#8B2500")
PCA_color_gradient <- brewer.pal(9, name="YlOrBr")[c(3,4,5,6,7,8,9)]

OutFilename <- paste(OutDir,"/Biplot_attribution.png",sep="")
png(OutFilename, 1200, 800)
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = PCA_color_gradient,
             repel = TRUE     # Avoid text overlapping
)
dev.off()

# Compute hierarchical clustering on principal components
res.pca4 <- PCA(SP_as_col, ncp = 3, graph = FALSE)
res.hcpc <- HCPC(res.pca4, graph = FALSE)

OutFilename <- paste(OutDir,"/PCA_score_dendrogram.png",sep="")
png(OutFilename, 1200, 800)
fviz_dend(res.hcpc, 
          cex = 0.7,                     # Label size
          palette = "jco",               # Color palette see ?ggpubr::ggpar
          rect = TRUE, rect_fill = TRUE, # Add rectangle around groups
          rect_border = "jco",           # Rectangle color
          labels_track_height = 0.8      # Augment the room for labels
)
dev.off()

OutFilename <- paste(OutDir,"/PCA_score_clusters.png",sep="")
png(OutFilename, 1200, 800)
fviz_cluster(res.hcpc,
             repel = TRUE,            # Avoid label overlapping
             show.clust.cent = TRUE, # Show cluster centers
             palette = "jco",         # Color palette see ?ggpubr::ggpar
             ggtheme = theme_bw(),
             main = "Factor map"
)
dev.off()

```

## Discard time series
calculated: discard = catch-landings
```{r}
# collate data
head(df3)

# check to see if there are any columns in df3 that have NA values
list_na <- colnames(df3)[apply(df3, 2,anyNA)]

# calculate discards - put this into df3 dataframe not new discards dataframe - adjusted script below to match
df3$discard_tonnes <- df3$fleet_removals_tonnes - df3$fleet_landing_tonnes

# Create new dataframes that is total discards across all fleets (per species and year) and across all species (per fleet)
discardsBySpecies <- df3 %>%
  group_by(Year, species_id, Group) %>%
  dplyr::summarise(TotalDiscards = sum(discard_tonnes))

discardsByFleet <- df3 %>%
  group_by(Year, Fleet.name) %>%
  dplyr::summarise(TotalDiscards = sum(discard_tonnes))

# Convert any NA with zeros
discardsBySpecies[is.na(discardsBySpecies)] <- 0
discardsByFleet[is.na(discardsByFleet)] <- 0

# Filter out any years that don't make sense
discardsBySpecies <- discardsBySpecies %>% dplyr::filter(Year > 0)
discardsByFleet <- discardsByFleet %>% dplyr::filter(Year > 0)

# check the maximum discard  
ymax <- 1.05 * max(discardsBySpecies$TotalDiscards, na.rm = TRUE)
ymin <- 0.95 * min(discardsBySpecies$TotalDiscards, na.rm = TRUE)
if (ymin < 0) { ymin <- 0 }

# plot the discards for each species
nLoop <- ceiling (nSPName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Total_Discards_per_species-page",iLoop,".png",sep="")
    check_name <- SpeciesNames[counter1:counter2]  
    extractC <- dplyr::filter(discardsBySpecies, Group %in% check_name)
    ggplot(extractC, aes(x = Year,  y = TotalDiscards))+
      geom_line(color = tscolor, size = 1.2) +
      #geom_point() +
      #ylim(ymin, ymax)+ 
      theme(legend.position = "none")+
      labs(
        title = "Discard tonnes of species by species",
        x = "Year",
        y = "Amount of catch discarded (tonnes)"
      ) +
    facet_wrap(~ Group, scales = 'free_y', ncol = 6) +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
}

# check the maximum discard  
ymax <- 1.05 * max(discardsByFleet$TotalDiscards, na.rm = TRUE)
ymin <- 0.95 * min(discardsByFleet$TotalDiscards, na.rm = TRUE)
if (ymin < 0) { ymin <- 0 }

# have a look at each species by fleet
nLoop <- ceiling (nFName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Total_Discards_per_fleet-page",iLoop,".png",sep="")
    check_name <- FleetNames[counter1:counter2]  
    extractC <- dplyr::filter(discardsByFleet, Fleet.name %in% check_name)
    ggplot(extractC, aes(x = Year,  y = TotalDiscards))+
      geom_line(color = tscolor, size = 1.2) +
      #geom_point() +
      #ylim(ymin, ymax)+ 
      theme(legend.position = "none") +
      labs(
        title = "Discarded tonnes of catch by fleet",
        x = "Year",
        y = "Amount of catch discarded (tonnes)"
      ) +
    facet_wrap(~ Fleet.name, scales = 'free_y', ncol = 6) +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
}


```

## Discard rate  
Dependent on discard time series  (discard = catch-landings)
discard_rate = (catch-landings)/catch  
```{r}
# collect data
head(df3)

# calculate discard rate
df3$discard_rate <- df3$discard_tonnes / df3$fleet_removals_tonnes

discard_stats <- df3 %>% 
  dplyr::group_by(Fleet.name, Year) %>% 
  dplyr::summarise(discard_mean = mean(discard_rate, na.rm = TRUE), 
                   discard_mean_sd = sd(discard_rate, na.rm = TRUE),
                   discard_n = n()) %>% 
  dplyr::filter(!is.na(Fleet.name))

# Reset any NAs (std deviations when n is 1)
discard_stats[is.na(discard_stats)] <- 0
discard_stats$max_CI <- discard_stats$discard_mean + (1.96 * discard_stats$discard_mean_sd / sqrt(discard_stats$discard_n))
discard_stats$min_CI <- discard_stats$discard_mean - (1.96 * discard_stats$discard_mean_sd / sqrt(discard_stats$discard_n))

# maximum and minimun discard rates
ymax <- 1.05 * max(discard_stats$max_CI, na.rm = TRUE)
ymin <- 0.95 * min(discard_stats$min_CI, na.rm = TRUE)
if (ymin < 0) { ymin <- 0 }

# plot the discard rate per fleeet
nLoop <- ceiling (nFName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Discard_rates_per_fleet-page",iLoop,".png",sep="")
    check_name <- FleetNames[counter1:counter2]  
    extractC <- dplyr::filter(discard_stats, Fleet.name %in% check_name)
    ggplot(extractC, aes(x = Year,  y = discard_mean))+
      geom_line(color = tscolor, size = 1.2) +
      #geom_point() +
      #ylim(ymin, ymax)+ 
      geom_line(aes(y = max_CI, color=tscolor), linetype="twodash") +
      geom_line(aes(y = min_CI, color=tscolor), linetype="twodash") +
      theme(legend.position = "none")+
      labs(
        title = "Discard rates by fleet",
        x = "Year",
        y = "Discard rates (proportion)"
      ) +
    facet_wrap(~ Fleet.name, scales = 'free_y', ncol = 6) +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
}

```

## Exploitation rate
using catch/biomass
```{r}
# collate data set
head(df)

# calculate exploitation rate
df$exploit_rate <- 100 * (df$catch_tonnes / df$biomass_tonnes)

# check for N values
list_na <- colnames(df)[apply(df, 2,anyNA)]

# check the maximum exploitation rate to make sure not over 100%
ymax <- 1.05 * max(df$exploit_rate)
subset(df, exploit_rate == max(exploit_rate)) # gives the row/s with the max exploitation rate - might need to check original data!

# plot trends in exploitation rate
nLoop <- ceiling (nSPName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Exploitation_rates_per_species-page",iLoop,".png",sep="")
    check_name <- SpeciesNames[counter1:counter2]  
    extractC <- dplyr::filter(df, Group %in% check_name)
    ggplot(data = extractC, mapping = aes(x = Year, y = exploit_rate)) +
      geom_line(color = tscolor, size = 1.2) +
      expand_limits(y=0) +
     theme(legend.position = "none")+
    labs(
      title = "Expolitation rate by species",
      x = "Year",
      y = "Percentage of stock exploited") +
    facet_wrap(~ Group, scales = 'free') +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
}

```

## Effort and Catch per unit effort (CPUE) time series
by gear type, vessel size 
Need real world data to calculate relevant information
```{r}

# read in effort data
load_effort_data <- 0   # 1 = Yes, 0 = No  - Set to 1 for observational data not EwE output
catch_in_effort_file <- 0  # 1 = catch in effort file, 0 = in a separate file

if (load_effort_data > 0) {
  EffortFile <- paste(mainDir,"/",InputsubDir,"/","effort_annual.csv",sep="")
  dfEffort <- read.csv(EffortFile, header = FALSE)  
  # Assumes column 1 is year, column 2 is FleetName, column 3 is effort in days
  
  # Load catch by metier data if required
  if (catch_in_effort_file < 1){
    CatchFleetFile <- paste(mainDir,"/",InputsubDir,"/","catch_fleet_annual.csv",sep="")
    dfCatchFleet <- read.csv(CatchFleetFile, header = FALSE)  
    # Assumes column 1 is year, column 2 is FleetName, column 3 is catch in tonnes
  }

  if (catch_in_effort_file < 1){
    dfFleetDat <- merge(dfEffort, dfCatchFleet, by=c("Year","Fleet.name"))
  } else {
    dfFleetDat <- dfEffort
  }

  dfFleetDat$CPUE <- dfFleetDat$TotCatch / dfFleetDat$Effort

  # Plot effort
  ymax <- 1.05 * max(dfFleetDat$Effort, na.rm = TRUE)
  ymin <- 0.95 * min(dfFleetDat$Effort, na.rm = TRUE)
  if (ymin < 0) { ymin <- 0 }
  
  # plot trends in exploitation rate
  nLoop <- ceiling (nFName / nPanel)
  counter1 <- 1
  counter2 <- nPanel
  for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Total_Effort_per_fleet-page",iLoop,".png",sep="")
    check_name <- FleetNames[counter1:counter2]  
    extractC <- dplyr::filter(dfFleetDat, Fleet.name %in% check_name)
    ggplot(data = extractC, mapping = aes(x = Year, y = Effort)) +
      geom_line(color = tscolor, size = 1.2) + 
      #geom_point() +
      #ylim(ymin, ymax) + 
      expand_limits(y=0) +
      theme(legend.position = "none")+
      labs(
        title = "Effort by fleet",
        x = "Year",
        y = "Effort (days)") +
    facet_wrap(~ Fleet.name, scales = 'free') +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
  }
  
  # Plot by CPUE
  ymax <- 1.05 * max(dfFleetDat$CPUE, na.rm = TRUE)
  ymin <- 0.95 * min(dfFleetDat$CPUE, na.rm = TRUE)
  if (ymin < 0) { ymin <- 0 }
  
  nLoop <- ceiling (nFName / nPanel)
  counter1 <- 1
  counter2 <- nPanel
  for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Total_CPUE_per_fleet-page",iLoop,".png",sep="")
    check_name <- FleetNames[counter1:counter2]  
    extractC <- dplyr::filter(dfFleetDat, Fleet.name %in% check_name)
    ggplot(data = extractC, mapping = aes(x = Year, y = CPUE)) +
      geom_line(color = tscolor, size = 1.2) + 
      #geom_point() +
      #ylim(ymin, ymax) + 
      expand_limits(y=0) +
      theme(legend.position = "none")+
      labs(
        title = "CPUE by fleet",
        x = "Year",
        y = "CPUE (tonnes/days)") +
    facet_wrap(~ Fleet.name, scales = 'free') +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel

  }
}

```

# Economic Indicators  
## Often not collected or not regualrly and not all at the same scale as the fishery (often only regional or national) - location for future refinement into the future

## Cost of fishing  
```{r}

# Total cost - Use fixed costs x effort.

# Breakdown of costs - This is not EwE model generated

```


## Total value of fishery  
# Using prices (e.g. beach prices) - this is not EwE model generated so use value from EwE
```{r}

# value data
value_from_file <- 1   # 1 if file contains value time series (as you get from EwE), 0 of need to calculate it from catch * price

if (value_from_file > 0) {

  ValueFile <- paste(mainDir,"/",InputsubDir,"/","value_annual.csv",sep="")
  value <- read.csv(ValueFile, header = T, skip = skip_this, check.names = FALSE) #   because csv file has headers - will need to skip the first 9 rows; check names makes sure an X isn't added before the number for the species
  names(value)[1] <- 'Year'   # changes the name of the first column to year instead of 
  val <- as.data.frame(value) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "value_tonnes")
  val$value_tonnes <- area_model * val$value_tonnes / 1000.0
  dfvalue <- full_join(val, id2) # data frame with biomass, catch and species names

} else {
  Price_ID <- read.csv("Prices_ID.csv")
  dfvalue <- merge(df, Price_ID, by = c("Group"))
  dfvalue$value_tonnes <- dfvalue$landings_tonnes * Price / 1000.0
}
  
#Value = $ per kilo of species
nLoop <- ceiling (nSPName / nPanel)
counter1 <- 1
counter2 <- nPanel
for (iLoop in 1:nLoop) {
    outPlotName <- paste(OutDir,"/Value_per_species-page",iLoop,".png",sep="")
    check_name <- SpeciesNames[counter1:counter2]  
    extractC <- dplyr::filter(dfvalue, Group %in% check_name)
    ggplot(data = extractC, mapping = aes(x = Year, y = value_tonnes)) +
      geom_line(color = tscolor, size = 1.2) +
      expand_limits(y=0) +
     theme(legend.position = "none")+
    labs(
      title = "Value by species",
      x = "Year",
      y = "Value (Thousands of $)") +
    facet_wrap(~ Group, scales = 'free') +
    theme(axis.text.y=element_text(size=8),axis.text.x=element_text(size=8), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))

    ggsave(file=outPlotName)
    
    counter1 <- counter1 + nPanel
    counter2 <- counter2 + nPanel
}

# Gross Value of the Fishery
gvp_calc <- dfvalue %>%
  group_by(Year) %>%
  dplyr::summarise(GVP = sum(value_tonnes))

# plot the index
plot_gvp_indx <- paste(OutDir,"/gvp_indx.png",sep="")
ggplot(gvp_calc, aes (x = Year, y = GVP)) +
  geom_line(color = aggtscolor, size = 1.5) +
  theme(legend.position = "none")+
  labs(
    title = "GVP time series",
    x = "Year",
    y = "GVP (Thousand $)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_gvp_indx)
```

## Fisheries' ecconomic contribution - This is not EwE model generated.
```{r}

# Total economic GDP contribution


# Employment - fishing sector 
# Assumes the total cost of fishing - assume x number of jobs per gear type


```


# Ecological Indicators - overall

## Calculate biomass time series  
1/(biomass/landings)
```{R}
# collate data
head(df)

# biomass time series using 1/(biomass/landings)
# Sum biomass of those species with landings and the calculate the index
biomass_calc_tmp <-df %>% dplyr::filter(landings_tonnes > 0)
biomass_calc <- biomass_calc_tmp %>%
  group_by(Year) %>%
  dplyr::summarise(TotAvailBio = sum(biomass_tonnes), TotLandings = sum(landings_tonnes))
biomass_calc$bioindx  <- 1.0 / (biomass_calc$TotAvailBio / biomass_calc$TotLandings) 

# plot the index
plot_biomass_indx <- paste(OutDir,"/one_on_bio_on_landings_indx.png",sep="")
ggplot(biomass_calc, aes (x = Year, y = bioindx)) +
  geom_line(color = aggtscolor, size = 1.5) +
  labs(
    title = "1/(Biomass/Landings) time series",
    x = "Year",
    y = "1/(Biomass/Landings)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_biomass_indx)

```

## Biomass ratios (piscivorous:zooplanktivorous fish; pelagic:demersal)
# Read in classificaiton from file - or should we use Reg Watson's classification? 
# Then calculate the ratios

# Assumes use biomass_annual.csv and assume speices-list.csv contains categorization of the groups according to size and calculate (as per FISHMIP calculations)
```{R}
# collate data
#head(df)

# get aggregate values - Pelagic:Demersal
PDtmp <- df %>%
  group_by(Year, PelDemID) %>%
  dplyr::summarise(BioPerClass = sum(biomass_tonnes), CatPerClass = sum(biomass_tonnes))
PDindB <- dcast(PDtmp, Year ~ PelDemID, value.var = "BioPerClass")
PDindB[is.na(PDindB)] <- 0 # Replace NA with zeros
PDindB$PDb <- PDindB$Pelagic / PDindB$Demersal

PDindC <- dcast(PDtmp, Year ~ PelDemID, value.var = "CatPerClass")
PDindC[is.na(PDindC)] <- 0 # Replace NA with zeros
PDindC$PDc <- PDindC$Pelagic / PDindC$Demersal

PDind <- merge(PDindB, PDindC, by = c("Year"))

# plot the index
plot_pd_indx <- paste(OutDir,"/pelagic_dermsal_biomass_ratio_indx.png",sep="")
ggplot(PDind, aes (x = Year, y = PDb), ) +
  geom_line(color = aggtscolor, size = 2) +
  geom_line(aes (x = Year, y = PDc), color = aggtscolor2, size = 1.2) +
  theme(legend.position = "right")+
  expand_limits(y=0.5) +
  labs(
    title = "Pelagic:Demersal time series",
    subtitle = "Dark line is biomass, light line is catch",
    x = "Year",
    y = "Pelagic:Demersal"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_pd_indx)


# get aggregate values - Piscivorous:Zooplanktivorous
PZtmp <- df %>%
  group_by(Year, PISCZOOPL) %>%
  dplyr::summarise(BioPerClass = sum(biomass_tonnes), CatPerClass = sum(biomass_tonnes))
PZindB <- dcast(PZtmp, Year ~ PISCZOOPL, value.var = "BioPerClass")
PZindB[is.na(PZindB)] <- 0 # Replace NA with zeros
PZindB$PZb <- PZindB$Piscivorous / PZindB$Planktivorous

PZindC <- dcast(PZtmp, Year ~ PISCZOOPL, value.var = "CatPerClass")
PZindC[is.na(PZindC)] <- 0 # Replace NA with zeros
PZindC$PZc <- PZindC$Piscivorous / PZindC$Planktivorous

PZind <- merge(PZindB, PZindC, by = c("Year"))

# plot the index
plot_pd_indx <- paste(OutDir,"/pisciv_zoopl_biomass_ratio_indx.png",sep="")
ggplot(PZind, aes (x = Year, y = PZb), ) +
  geom_line(color = aggtscolor, size = 2) +
  geom_line(aes (x = Year, y = PZc), color = aggtscolor2, size = 1.2) +
  theme(legend.position = "right")+
  expand_limits(y=0.5) +
  labs(
    title = "Piscivore:Zooplanktivore time series",
    subtitle = "Dark line is biomass, light line is catch",
    x = "Year",
    y = "Piscivore:Zooplanktivore"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_pd_indx)

```


## CVi vs CVt
```{r}
## Make sure have SP_as_col
CdataS <- df

# Replace spaces in names with "_"
CdataS$Group <- gsub("\\(", "", CdataS$Group)
CdataS$Group <- gsub("\\/", "", CdataS$Group)
CdataS$Group <- gsub(")", "", CdataS$Group)
CdataS$Group <- gsub("&", "", CdataS$Group)
CdataS$Group <- gsub("-", "", CdataS$Group)
CdataS$Group <- gsub(" ", "", CdataS$Group)
#CdataS$Group <- gsub("  ", " ", CdataS$Group)
#CdataS$Group <- gsub(" ", "_", CdataS$Group)
#SP_as_colA <- dcast(CdataS, Year ~ Group, value.var = "TotalYield")

SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "landings_tonnes")

# Replace NA with zeros
SP_as_colA[is.na(SP_as_colA)] <- 0

# Strip out columns of all zeros
SP_as_col <- SP_as_colA[, colSums(SP_as_colA != 0) > 0]

## Melted version that have to cast
outNameA <- paste(OutDir,"/CV_3year_period.csv",sep="")
outNameB <- paste(OutDir,"/CV_5year_period.csv",sep="")
plot_indx <- paste(OutDir,"/CV_indx.png",sep="")

nCol <- dim(SP_as_col)[2]
NameEx <- colnames(SP_as_col)[2:nCol]
nSPNameEx <- nCol - 1
#NameEx[nSPNameEx]
NameExT <- append(NameEx,"Total")
SP_as_col$Total <- rowSums(SP_as_col[ , c(2:nCol)], na.rm=TRUE)

windowA <- 3
windowB <- 5

funMeanA <- function(x) zoo::rollmean(x, windowA, na.pad=TRUE, align="right")
funMeanB <- function(x) zoo::rollmean(x, windowB, na.pad=TRUE, align="right")
funSDA <- function(x) zoo::rollapply(x, width = windowA, FUN = sd, fill=NA, align='right') 
funSDB <- function(x) zoo::rollapply(x, width = windowB, FUN = sd, fill=NA, align='right') 

dfoutSDA <- SP_as_col %>% 
  mutate_at(NameExT, funSDA)
dfoutSDB <- SP_as_col %>% 
  mutate_at(NameExT, funSDB)
dfoutMA <- SP_as_col %>% 
  mutate_at(NameExT, funMeanA)
dfoutMB <- SP_as_col %>% 
  mutate_at(NameExT, funMeanB)

NLose <- windowA - 1
dfCVA <- 100.0 * dfoutSDA / dfoutMA
dfCVA[is.na(dfCVA)] <- 0 # Replace NA with zeros
dfCVtest <- subset (dfCVA, select = -c(Year, Total))
dfCVA$SppAboveCVt <- rowSums(dfCVtest > dfCVA$Total)
dfCVA$PropAboveCVt <- dfCVA$SppAboveCVt / nSPNameEx
dfCVA$Year <- dfoutSDA$Year
dfCVA <- dfCVA[-c(1:NLose),] # Drop rows of NAs from the start

NLose <- windowB - 1
dfCVB <- 100.0 * dfoutSDB / dfoutMB
dfCVB[is.na(dfCVB)] <- 0 # Replace NA with zeros
dfCVtest <- subset (dfCVB, select = -c(Year, Total))
dfCVB$SppAboveCVt <- rowSums(dfCVtest > dfCVB$Total)
dfCVB$PropAboveCVt <- dfCVB$SppAboveCVt / nSPNameEx
dfCVB$Year <- dfoutSDB$Year
dfCVB <- dfCVB[-c(1:NLose),] # Drop rows of NAs from the start

# save results file
write.csv(dfCVA, file = outNameA, row.names = FALSE)
write.csv(dfCVB, file = outNameB, row.names = FALSE)

# Plot results
ggplot(data = NULL) +
  geom_line(data = dfCVA, aes (x = Year, y = PropAboveCVt), color = aggtscolor, size = 1.5) +
  geom_line(data = dfCVB, aes (x = Year, y = PropAboveCVt), color = aggtscolor2, size = 1.2, linetype="twodash") +
  theme(legend.position = "right")+
  expand_limits(y=0) +
  labs(
    title = "Proportion of species with CV > CVtotal",
    x = "Year",
    y = "Proportion"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

```

## Calculations for a number of general indices
Mean length (weight or max length) in a community or catch- Assumes Linf is in Species_ID.csv file
Mean trophic level of community, catch - Trophic level calculated by EwE model based on diet (not biomass).
Mean longevity - Assumes MaxAge is in Species_ID.csv file
Proporation of large fish (LFI)  - based on Linf in Species_ID.csv file
```{r}
# This assumes that size classes have been loaded as part of the Species_ID file
#head(df)
KeepThese <- c("TEP","Piscivorous","Planktivorous","Invert")
KeepFish <- c("Piscivorous","Planktivorous")
minYear <- min(df$Year)
maxYear <- max(df$Year)
nYear <- maxYear - minYear + 1
YearNum <- as.data.frame(seq(minYear, maxYear, by = 1))

dfCalc <- data.frame(matrix(0, ncol = 9, nrow = nYear))
rownames(dfCalc)[1:nYear] <- YearNum[,1]
colnames(dfCalc)[1:9] <- c("Year","meanLengthBio","meanLengthCatch","meanTLBio","meanTLCatch","meanAgeBio","meanAgeCatch","LFIbio","LFIcatch")

# Combine dataframes
dftmp <- merge(df,tl_species, by = c("Year", "Group"))
dftmp <- subset (dftmp, select = -c(species_id.y,PelDemID.y:MaxAge_yr.y))
colnames(dftmp)[7:10] <- c("PelDemID","PISCZOOPL","Linf_cm","MaxAge_yr")
colnames(dftmp)[3] <- c("species_id")

counter <- 0
for (iYear in minYear:maxYear) {
  counter <- counter + 1
  
  # Do biomass calculations first
  dfExtract <- dplyr::filter(dftmp, Year == iYear & PISCZOOPL %in% KeepThese)
  dfExtract$SizeCalcB <- dfExtract$biomass_tonnes * dfExtract$Linf_cm
  dfExtract$TLB <- dfExtract$biomass_tonnes * dfExtract$trophic_level
  dfExtract$AgeB <- dfExtract$biomass_tonnes * dfExtract$MaxAge_yr
  meanL <- sum(dfExtract$SizeCalcB) / sum(dfExtract$biomass_tonnes)
  meanTL <- sum(dfExtract$TLB) / sum(dfExtract$biomass_tonnes)
  meanAge <- sum(dfExtract$AgeB) / sum(dfExtract$biomass_tonnes)
  dfCalc$Year[counter] <- iYear
  dfCalc$meanLengthBio[counter] <- meanL
  dfCalc$meanTLBio[counter] <- meanTL 
  dfCalc$meanAgeBio[counter] <- meanAge 
  
  # Do LFI for biomass
  dfExtract <- dplyr::filter(dfExtract, PISCZOOPL %in% KeepFish)
  totbio <- sum(dfExtract$biomass_tonnes)
  dfExtract <- dplyr::filter(dfExtract, Linf_cm > 40.0)
  totLFI <- sum(dfExtract$biomass_tonnes)
  LFI <- totLFI / totbio
  dfCalc$LFIbio[counter] <- LFI 

  # Now do it based on landings by only including those species that are fished
  dfExtract <- dplyr::filter(dftmp, Year == iYear)
  ndim <- dim(dfExtract)
  num_row <- ndim[1]
  dfExtract$Include <- 0
  for (i in 1:num_row ) {
    if(dfExtract$landings_tonnes[i] > 0) {
      dfExtract$Include[i] <- 1
    } else {
      dfExtract$Include[i] <- 0
    }
  }
  dfExtract <- dplyr::filter(dfExtract, Include > 0)
  dfExtract$SizeCalcL <- dfExtract$landings_tonnes * dfExtract$Linf_cm
  dfExtract$TLCatch <- dfExtract$landings_tonnes * dfExtract$trophic_level
  dfExtract$AgeC <- dfExtract$landings_tonnes * dfExtract$MaxAge_yr
  meanL <- sum(dfExtract$SizeCalcL) / sum(dfExtract$landings_tonnes)
  meanTL <- sum(dfExtract$TLCatch) / sum(dfExtract$landings_tonnes)
  meanAge <- sum(dfExtract$AgeC) / sum(dfExtract$landings_tonnes)
  dfCalc$meanLengthCatch[counter] <- meanL
  dfCalc$meanTLCatch[counter] <- meanTL 
  dfCalc$meanAgeCatch[counter] <- meanAge 
  
  # Do LFI for catch
  dfExtract <- dplyr::filter(dfExtract, PISCZOOPL %in% KeepFish)
  totbio <- sum(dfExtract$landings_tonnes)
  dfExtract <- dplyr::filter(dfExtract, Linf_cm > 40.0)
  totLFI <- sum(dfExtract$landings_tonnes)
  LFI <- totLFI / totbio
  dfCalc$LFIcatch[counter] <- LFI 

}

# save results file
outName <- paste(OutDir,"/Aggregate_indices.csv",sep="")
write.csv(dfCalc, file = outName, row.names = FALSE)

# Plot the results
plot_indx <- paste(OutDir,"/mean_size_bio_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanLengthBio), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean size time series - based on macrofauna biomass",
    x = "Year",
    y = "Size (cm)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_TL_bio_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanTLBio), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean trophic level series - based on macrofauna biomass",
    x = "Year",
    y = "Trophic level"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_Age_bio_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanAgeBio), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean age time series - based on macrofauna biomass",
    x = "Year",
    y = "Longevity (years)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_LFI_bio_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = LFIbio), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "LFI time series - based on macrofauna biomass",
    x = "Year",
    y = "LFI"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_size_landings_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanLengthCatch), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean size time series - based on landings",
    x = "Year",
    y = "Size (cm)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_TL_landings_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanTLCatch), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean trophic level series - based on landings",
    x = "Year",
    y = "Trophic level"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_Age_landings_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = meanAgeCatch), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "Mean age time series - based on landings",
    x = "Year",
    y = "Longevity (years)"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

plot_indx <- paste(OutDir,"/mean_LFI_landings_indx.png",sep="")
ggplot(dfCalc, aes (x = Year, y = LFIcatch), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "LFI time series - based on landings",
    x = "Year",
    y = "LFI"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

```


# Link and Watson 2019 indicators
* Ryther - catch per unit area (divide total catch by area of the model to get this value)
* Fogarty - total catch / total primary production (units are per mil - o/oo  where 0.001 is 1 o/oo)
* Friedland - use catch: Chlorophyll a (basically doing Fogarty but use Chl a instead if primary production is not available. For EwE calcaulte off primary production but also plot it up based on assuptions of biomass:C -> c: Chla -> final calculations

```{r}

# Ryther 
dfcat <- df %>%
  group_by(Year) %>%
  dplyr::summarise(tot_catch = sum(landings_tonnes))
dfcat$Ryther <- dfcat$tot_catch / area_model

# Fogarty 
# Start by getting the production values
production <- mortality * biomass
production$Year <- biomass$Year
dfProd <- as.data.frame(production) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "production")
dftmp <- full_join(dfProd, id2) # Reuse old temporary df
df1tmp <- full_join(dftmp, tl) # Reuse old temporary df
dfProd <- dplyr::filter(df1tmp, trophic_level == 1.0) # Intentional reuse
dfProd <- dplyr::filter(dfProd, IsDetritus == 0)

dftmp <- dfProd %>%
  group_by(Year) %>%
  dplyr::summarise(tot_prod = sum(production))  # Already per km2 as never multiplied production by area (and mortality and biomass is per km2)
dfLW <- full_join(dfcat, dftmp)
dfLW$Fogarty <- 1000.0 * dfLW$Ryther / dfLW$tot_prod

# Friedland 
# Calculate Chl a
if (chl_from_file < 1) {
  X_CN <- 5.7 # Redfield assumption
  X_CHLN <- 7.0 # Assumed ratio of N:Chl a
  dftmp <- as.data.frame(biomass) %>% 
    pivot_longer(-Year, names_to = "species_id", values_to = "biomass_per_area")
  dftmp1 <- full_join(dftmp, id2) # Reuse old temporary df
  dftmp <- full_join(dftmp1, tl) # Reuse old temporary df
  dfProd <- dplyr::filter(dftmp, trophic_level == 1.0) # Intentional reuse
  dfProd <- dplyr::filter(dfProd, IsDetritus == 0)
  dfProd$Chl <- 1000000000.0 * ((dfProd$biomass_per_area / (X_CN * 20.0)) / X_CHLN)    # From wet weight to N to Chl a
  thislinetype <- "dashed"
} else {
 dfProd <- dfChl 
 thislinetype <- "solid"
}

dftmp <- dfProd %>%
  group_by(Year) %>%
  dplyr::summarise(tot_chl = sum(Chl))  # Already per km2 
dfLW <- full_join(dfLW, dftmp)
dfLW$Friedland <- 1000.0 * dfLW$Ryther / dfLW$tot_prod

# Plots
outaplot <- paste(OutDir,"/Ryther_Friedland_Fogarty_indx.png",sep="")
check_name <- c("Ryther", "Friedland", "Fogarty")
dfLWplot <- dfLW %>% 
  pivot_longer(-Year, names_to = "Index")
dfLW <- dplyr::filter(dfLWplot, Index %in% check_name) 
ggplot(dfLW, aes(x=Year, y=value, group=Index)) +
  geom_line(aes(linetype = Index, colour=Index), size = 2) + 
  geom_hline(yintercept = 1, colour = "gray47", linetype="dashed", size=0.5) +
  theme_bw() + theme(axis.title=element_text(size=14,face="bold")) +
  ggtitle("Link and Watson system capacity indices") +
  labs(x="Year", y="System capacity index") +
  scale_colour_manual( values = c("darkgoldenrod1","darkcyan","black")) +
  scale_linetype_manual(values=c("solid", thislinetype, "solid"))
ggsave(file=outaplot)


```

# Cumualtive biomass-TL
```{r}

dfcat <- full_join(df, tl) # Reuse old temporary df

# Get cumulative biomass per TL increment - Using Biomass
minYear <- min(dfcat$Year)
maxYear <- max(dfcat$Year)
nYear <- maxYear - minYear + 1
YN <- seq(minYear,maxYear,1)
YearNum <- as.data.frame(YN)

cumRes <- data.frame(matrix(0, ncol = 8, nrow = nYear))
rownames(cumRes)[1:nYear] <- YearNum[,1]
colnames(cumRes)[1:8] <- c("Year","infTL","inflB","steepness","b1","b2","c","d")
  
dfcreated <- 0
  
for (iYear in minYear:maxYear) {
  thisYear <- iYear - minYear + 1
    
   # Filter by year
   dfCD <- filter(dfcat, Year == iYear)
    
  # sort by TL ascending
  dfCDsorted <- dfCD[order(dfCD$trophic_level), ]
    
  # calculate cumulative catch 
  dfCDsorted$cumB <- cumsum(dfCDsorted$landings_tonnes)
    
  # TotalBiomass
  TotB <- max(dfCDsorted$cumB)
    
  # Now make column PropCumB
  dfCDsorted$PropCumB <- dfCDsorted$cumB / TotB
    
  # Fit five-parameter regression - using drc
  fm1 <- drm(PropCumB~trophic_level, data=dfCDsorted, fct=baro5())
  dfCDsorted$curvefit = predict(fm1)
    
  # Store results for sorted materials
  if (dfcreated == 0) {
    dfBioResults <- dfCDsorted
    dfcreated <- 1
  } else {
    dfBioResults <-rbind(dfBioResults, dfCDsorted)
  }
    
  #plot(fm1)
  #ggplot(dfCDsorted, aes(x = TL)) +
  #  geom_point(aes(y = cumB), color ="deepskyblue3") +
  #  geom_point(aes(y = cumC), color ="darkorange") +
  #  geom_line(aes(y = curvefit), size = 1)
    
  # Calculate - B inflection and TL inflection (only do it for catch if non-zero)
  # This involves finding when the second derivative of the curve = 0
  # However the "e" coeffient given by fm1 is the inflection TL so simply read off the 
  # inflection point B using that TL value
  infTL <- fm1$fit$par[5]
  b1 <- fm1$fit$par[1]
  b2 <- fm1$fit$par[2]
  c <- fm1$fit$par[3]
  d <- fm1$fit$par[4]
  e <- infTL

  baro5eq = expression(c + ((d - c)/(1 + (1/(1 + exp((2 * b1 * b2/(b1 + b2)) * (log(x) - log(e))))) * (exp(b1 * (log(x) - log(e)))) + (1 - (1/(1 + exp((2 * b1 * b2/(b1 + b2)) * (log(x) - log(e)))))) * (exp(b2 * (log(x) - log(e)))))))
  x <- infTL
  infB <- eval(baro5eq)

  # Calculate - Steepness (the first derivative at the inflection point)
  dx2x <- D(baro5eq,"x")
  steep <- eval(dx2x)

  # Store indicator results
  cumRes[thisYear,1] <- iYear
  cumRes[thisYear,2] <- infTL
  cumRes[thisYear,3] <- infB
  cumRes[thisYear,4] <- steep
  cumRes[thisYear,5] <- b1
  cumRes[thisYear,6] <- b2
  cumRes[thisYear,7] <- c
  cumRes[thisYear,8] <- d
    
}
  

p0 <- ggplot(dfBioResults, aes(x = trophic_level, y = curvefit)) +
  geom_point(aes(colour = factor(Year))) +
  geom_line(aes(colour = factor(Year))) +
  scale_color_viridis(option = "D", discrete = TRUE) +
  theme(text = element_text(size = textsize)) 
  
# Plot 6 panels - the 3 indicators through time and 
# Reproduce plots from Libralato et al 2019 
 # Steep vs TL
# B vs TL
# Steep vs B
  
# 1. infTL through time
p1 <- ggplot(cumRes, aes(x = Year, y = infTL)) +
  geom_line(color ="deepskyblue3", size = linesize) +
  theme(text = element_text(size = textsize)) 
  
# 2. infB through time
p2 <- ggplot(cumRes, aes(x = Year, y = inflB)) +
  geom_line(color ="darkorange", size = linesize) +
  theme(text = element_text(size = textsize)) 
  
# 3. steep through time
p3 <- ggplot(cumRes, aes(x = Year, y = steepness)) +
  geom_line(color ="grey44", size = linesize) +
   theme(text = element_text(size = textsize)) 
  
# 4. Steep vs TL
p4 <- ggplot(cumRes, aes(x = infTL, y = steepness)) +
  geom_point() +
  theme(text = element_text(size = textsize)) 
  
# 5. B vs TL 
p5 <- ggplot(cumRes, aes(x = infTL, y = inflB)) +
  geom_point() +
  theme(text = element_text(size = textsize)) 
  
# 6. Steep vs B 
p6 <- ggplot(cumRes, aes(x = inflB, y = steepness)) +
  geom_point() +
  theme(text = element_text(size = textsize)) 
  
# Plot Catch through time too
nSP <- length(unique(dfcat$Group))
colPalette <- get_palette(c("#00AFBB", "#E7B800", "#FC4E07"), nSP)
  
pC <- ggplot(dfcat, aes(x = Year, y = landings_tonnes, fill = Group, order = Group)) +
  geom_bar(colour = "black", stat="identity", size = 0.1) +
  scale_fill_manual(values = colPalette) +
  labs(x="Years", y = "Catch") +  theme(legend.position = "none", text = element_text(size = 12))
  
# Plot Biomass
pB <- ggplot(dfcat, aes(x = Year, y = biomass_tonnes, fill = Group, order = Group)) +
  geom_bar(colour = "black", stat="identity", size = 0.1) +
  scale_fill_manual(values = colPalette) +
  labs(x="Years", y = "Biomass") +  theme(legend.position = "none", text = element_text(size = 12))
  
# Final panel plot
outPlotName <- paste(OutDir,"/Cumulative-plots-Catch.png",sep="")

# Arrange plots using arrangeGrob
# returns a gtable (gt)
#gt <- arrangeGrob(p0,   # Big # cumBio vs TL
#                  pC, pB, p1, p2, p3, p4, p5, p6, # All other plots
#                  ncol = 2, nrow = 6, 
#                  layout_matrix = rbind(c(1,1), c(2,2), c(3,3), c(4,5), c(6,7), c(8,9)))
# Add labels to the arranged plots
gt <- arrangeGrob(p0,   # Big # cumBio vs TL
                  pC, p1, p2, p3, p4, p5, p6, # All other plots
                  ncol = 2, nrow = 6, 
                  layout_matrix = rbind(c(1,1), c(2,2), c(3,4), c(5,6), c(7,8)))
# Add labels to the arranged plots
p <- as_ggplot(gt)                                 # transform to a ggplot
  #+ draw_plot_label(label = c("A", "B", "C", "D", "E", "F", "G", "H")) # Add labels
png(outPlotName, 1200, 800)
p
dev.off()


```

# Network analysis 
THis is currently not tracked dynamically - calculate separate and put result into Species_ID.csv

# Greenband
Follows the approach of Heath - where the allowed catch is proportional to production
```{r}
# Set up reference values
RefVal <- dfRef
RefVal$RefP <- RefVal$RefB * RefVal$RefM
idRef <- merge(id2, RefVal, by=c("species_id"))
idRef <- idRef %>% dplyr::filter(IsDetritus < 1)

# Estimate the initial slope
idRef$logP <- log10(idRef$RefP)
idRef$logB <- log10(idRef$RefB)
linreg <- lm(formula = logB ~ logP, data = idRef)
matrix_coef <- summary(linreg)$coefficients 
reg_slope <- round(matrix_coef[2,1],3)
reg_const <- round(matrix_coef[1,1],3)
band_slope <- reg_slope + 1.0   # This is the slope of the grend band for the rest of the work
lm_equation <- paste("y = ", reg_const, " + ", reg_slope, " x",sep="")
this_r2 <- round(summary(linreg)$r.squared,3)
lm_R2 <- paste("R2 = ",this_r2,sep="")

ymin <- 1e-8
xmin <- 1e-6
ymax <- 1e+5
xmax <- 1e+5
lymin <- log10(1e-8)
lxmin <- log10(1e-6)
lymax <- log10(1e+5)
lxmax <- log10(1e+5)

outaplot <- paste(OutDir,"/Green_Band_Reference_Plot.png",sep="")
ggplot(data = idRef, aes(x = RefP, y = RefB)) + 
    geom_point() +
    geom_smooth(method='lm') +
    scale_x_log10(limits=c(xmin, xmax)) + scale_y_log10(limits=c(ymin, ymax)) +
    labs(x="Production", y = "Biomass") +
    annotate("text", x=1e-4, y=3e+4, label= lm_equation) + 
    annotate("text", x = 1e-4, y=1e+4, label = lm_R2) +
    theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"))
ggsave(file=outaplot)

# Get production once fished
production <- mortality * biomass
production$Year <- biomass$Year
dfProd <- as.data.frame(production) %>% 
  pivot_longer(-Year, names_to = "species_id", values_to = "Production")
dftmp <- full_join(dfProd, id2) # Reuse old temporary df
dfBand <- full_join(dftmp, df) 
dfBand <- dfBand %>% dplyr::filter(Class_Code > 0)

# Rate in comparison to green band
# Equations for key lines
# Max_allowable  C = 0.5 * P
# Max_green_band  C = P ^ band_slope
# Min_green_band  C = C_Max_green_band * 0.01
# Realised Max_green_band  C = min(Max_allowable, Max_green_band)
# Realised Min_green_band  C = min(Max_allowable, Min_green_band)
# Light 1 - L
# Acceptable 2 - A
# Fail 3 - F
  
dfBand$MaxAllow <- 0.5 * dfBand$Production
dfBand$MaxGreenBand <- dfBand$Production ^ band_slope
dfBand$MinGreenBand <- dfBand$MaxGreenBand * 0.01
dfBand$RealMax <- ifelse(dfBand$MaxAllow < dfBand$MaxGreenBand, dfBand$MaxAllow , dfBand$MaxGreenBand)
dfBand$RealMin <- ifelse(dfBand$MaxAllow < dfBand$MinGreenBand, dfBand$MaxAllow , dfBand$MinGreenBand)
dfBand$DistortScore <- ifelse(dfBand$catch_tonnes < dfBand$RealMin, "L", (ifelse(dfBand$catch_tonnes >= dfBand$RealMax, "F", "A")))
  
dfScored <- merge(dfBand, dfRef, by=c("species_id"))
names(dfScored)[names(dfScored) == "species_id.x"] <- "species_id"
names(dfScored)[names(dfScored) == "Classification.x"] <- "Classification"
names(dfScored)[names(dfScored) == "Class_Code.x"] <- "Class_Code"

dfScored$Rel_B <- dfScored$biomass_tonnes / dfScored$RefBo
dfScored$Min_B <- ifelse(dfScored$Class_Code == 1, 0.5, 
                           (ifelse(dfScored$Class_Code == 2, 0.3, 
                                   (ifelse(dfScored$Class_Code == 3, 0.35, 
                                           (ifelse(dfScored$Class_Code == 4, 0.2, 
                                                   (ifelse(dfScored$Class_Code == 5, 0.4, 
                                                           (ifelse(dfScored$Class_Code == 6, 0.4, 0.6)))))))))))
dfScored$Max_B <- ifelse(dfScored$Class_Code == 1, 0.7, 
                           (ifelse(dfScored$Class_Code == 2, 0.6, 
                                   (ifelse(dfScored$Class_Code == 3, 0.4, 
                                           (ifelse(dfScored$Class_Code == 4, 0.4, 
                                                   (ifelse(dfScored$Class_Code == 5, 0.5, 
                                                           (ifelse(dfScored$Class_Code == 6, 0.5, 0.7)))))))))))
dfScored$B_Score <- ifelse(dfScored$Rel_B > dfScored$Max_B, "L", (ifelse(dfScored$Rel_B <= dfScored$Min_B, "F", "A")))
  
# Assumes Thresholds
# 
#  CLass    ID    Min   Max
#
# Vulnerable  1   0.5   0.7  
# Habitat     2   0.3   0.6
# Byproduct   3   0.35  0.4
# Bycatch     4   0.2   0.4
# Target      5   0.4   0.5
# Robust      6   0.4   0.5
# Hub         7   0.6   0.7
  
# Aggregate Results
dfAggScore_Distort <- dfScored %>% dplyr::count(Year, DistortScore)
dfAggScore_B <- dfScored %>% dplyr::count(Year, B_Score)
  
dfAggScore_Distort <- dfAggScore_Distort %>% dplyr::filter(!is.na(DistortScore))
dfAggScore_B <- dfAggScore_B %>% dplyr::filter(!is.na(B_Score))
  
# Plot Scores through time - as bar plot
ggplot(data = dfAggScore_Distort, aes(x = Year, y = n, fill = DistortScore)) + geom_bar(colour = "black", stat="identity", size = 0.1) +
    scale_fill_manual(values = c("#00AFBB", "#E7B800", "#FC4E07")) + theme_bw() +
    labs(x="Years", y = "Ratings") +
    theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"))
  
# Plot Scores through time - as bar plot
ggplot(data = dfAggScore_B, aes(x = Year, y = n, fill = B_Score)) + geom_bar(colour = "black", stat="identity", size = 0.1) +
    scale_fill_manual(values = c("#00AFBB", "#E7B800", "#FC4E07")) + theme_bw() +
    labs(x="Years", y = "Ratings") +
    theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"))
 
Bounds <- data.frame(matrix(0, ncol = 6, nrow = 10))
colnames(Bounds)[1:6] <- c("P","MaxAllow","MaxGreenBand","MinGreenBand","MinC","MaxC")
listP <- c(1.00E-19, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000)
Bounds$P <- listP
Bounds$MaxAllow <- 0.5 * Bounds$P
Bounds$MaxGreenBand <- Bounds$P ^ band_slope
Bounds$MinGreenBand <- Bounds$MaxGreenBand * 0.01
Bounds$MaxC <- ifelse(Bounds$MaxAllow < Bounds$MaxGreenBand, Bounds$MaxAllow, Bounds$MaxGreenBand)
Bounds$MinC <- ifelse(Bounds$MaxAllow < Bounds$MinGreenBand, Bounds$MaxAllow, Bounds$MinGreenBand)
BoundsMelt <- melt(Bounds,"P") 
names(BoundsMelt)[2] <- 'Variables'
names(BoundsMelt)[3] <- 'CValue'

nSpCode <- max(dfScored$Class_Code)
for (i in 1:nSpCode) {
  dfThisCode <- dfScored %>% dplyr::filter(Class_Code == i)
  outPlotName <- paste(OutDir,"/GreenBand-",dfThisCode$Classification[1],".png",sep="")
  
  dfMin <- BoundsMelt %>% dplyr::filter(Variables == "MinC")
  dfMax <- BoundsMelt %>% dplyr::filter(Variables == "MaxC")

  #ymin <- min(dfThisCode$C) * 0.1
  #xmin <- min(dfThisCode$P) * 0.1
  #ymax <- max(dfThisCode$C) * 10.0
  #xmax <- max(dfThisCode$P) * 10.0
  
  ggplot(data = dfThisCode, aes(x = Production, y = catch_tonnes)) + 
    geom_point(data = dfThisCode, aes(size = Year, color = Group)) +
    geom_line(data = dfThisCode, aes(color = Group)) +
    geom_line(data = dfMin, aes(x = P, y = CValue), linetype = "dashed", color = "black") +
    geom_line(data = dfMax, aes(x = P, y = CValue), linetype = "dashed", color = "black") +
    scale_size_continuous(range = c(1, 3)) +
    scale_x_log10(limits=c(xmin, xmax)) + scale_y_log10(limits=c(ymin, ymax)) +
    labs(x="Production", y = "Catch") +
    theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"))
  
  ggsave(file=outPlotName)
  
}
```

# Gao calculation
sin = weighted degree in (similarly for sout)
<s> is the is the average weighted degree (density)
H=STDEVinSTDEVout/〈s〉
S=(〈sin*sout〉−〈sin〉〈sout〉)/(STDEVinSTDEVout )
```{r}
#Rules
# Update how do vertex mapping
new_rule <- data.frame(type="vertex", fromcls="network", fromattr="na",
                       tocls="igraph", toattr=NA,
                       stringsAsFactors=FALSE)
# combine with the default rules
rules <- rbind( attrmap(), new_rule )
rules

# To calculate the degree in and out through time
# Load base consumption matrix
origQ <- read.csv("consumption_matrix.csv", header = T, row.names=1)

# Calculate Gao index for that value of <s> so can check on whether above or below resilience horizon
c_coefft <- 0.019
b_coefft <- 0.8931
a_coefft <- 5.3384
H_ref <- 5.32
s_ref <- 6.97

# Get network indices through time - assumes that ref is for year 1
minYear <- min(df$Year)
maxYear <- max(df$Year)
nYear <- maxYear - minYear + 1
nSP <- length(unique(df$species_id))
Gaoindx <- data.frame(matrix(0, ncol = 7, nrow = nYear))
colnames(Gaoindx)[1:7] <- c("Year","Gao_density","Gao_s","Gao_H","Gao_indx","resil_H","GaoScore")
rownames(Gaoindx)[1:nYear] <- seq(minYear, maxYear, by=1) 
dfDeg <- data.frame(matrix(0, ncol = 3, nrow = nSP))
colnames(dfDeg)[1:3] <- c("species_id","Din","Dout")

for (iYear in minYear:maxYear) {
  thisYear <- iYear - minYear + 1
  extractdf <- df %>% dplyr::filter(Year == iYear)
  dftmp <- merge(extractdf, dfRef, by=c("species_id"))
  dftmp$rel_B <-dftmp$biomass_tonnes / dftmp$RefBo
  dftmp$rel_B[dftmp$rel_B < 0.00001] <- 0  # So ave an effect on flows of being highly depleted
  newQ <- origQ * dftmp$rel_B
  for(iSP in i:nSP){  # Treat iSP as col_ID doing calculation on
    dfPred <- dftmp %>% dplyr::filter(species_id == iSP)
    bioPred <- dfPred$rel_B
    dietData <- newQ * bioPred
  }
    
  # Calculate Degree in and Degree out
  gg <- network(dietData, directed=TRUE, loops=TRUE, vertex.names=nodes)  # Create network from dietData
  gn <- asIgraph(gg, amap=rules)
  l <- asDF(gn)
  str(l)
  l$edges
  l$vertexes
  g <- asIgraph(l$edges, vertices=l$vertexes, directed=TRUE)
  set_vertex_attr(g, "label", value=l$vertexes[,2])
  edges <- get.edgelist(g)   # Can also be extracted using E(g)
  nodes <- V(g)$vertex.names    # Name of vertices
  food_tidy <- as_tbl_graph(g, directed = TRUE)
  centRes <- centrality(food_tidy)
  d_in <- degree(g, mode = "in", normalized = FALSE)
  d_out <- degree(g, mode = "out", normalized = FALSE)
    
  # Store value
  dfDeg$species_id <- seq(1, nSP, by=1)
  dfDeg$Din <- d_in
  dfDeg$Dout <- d_out
 
  # Calculate H
  GaoStep1 <- merge(dftmp, dfDeg, by=c("species_id")) # intentionally reused
  GaoStep1$WgtDin <- GaoStep1$Din * GaoStep1$biomass_tonnes / area_model
  GaoStep1$WgtDout <- GaoStep1$Dout * GaoStep1$biomass_tonnes / area_model
  GaoStep1$WDIWDO <- GaoStep1$WgtDin * GaoStep1$WgtDout

  step1 <- as.data.frame(GaoStep1$WgtDin)
  colnames(step1)[1] <- "x"
  step2 <- as.data.frame(GaoStep1$WgtDout)
  colnames(step2)[1] <- "x"
  step1 <- rbind(step1, step2)
  Gao_density <- mean(step1$x)
  Gao_meanWDIWDO <- mean(GaoStep1$WDIWDO)
  Gao_meanWgtDin <- mean(GaoStep1$WgtDin)
  Gao_meanWgtDout <- mean(GaoStep1$WgtDout)
  Gao_sdWgtDin <- sd(GaoStep1$WgtDin)
  Gao_sdWgtDout <- sd(GaoStep1$WgtDout)
  Gao_s <- abs(Gao_meanWDIWDO-(Gao_meanWgtDin*Gao_meanWgtDout))/(Gao_sdWgtDin*Gao_sdWgtDout)
  Gao_H <- (Gao_sdWgtDout*Gao_sdWgtDin)/Gao_density
  Gindx <- Gao_density+Gao_H*Gao_s
  
  Gaoindx[thisYear,1] <- iYear
  Gaoindx[thisYear,2] <- Gao_density
  Gaoindx[thisYear,3] <- Gao_s
  Gaoindx[thisYear,4] <- Gao_H
  Gaoindx[thisYear,5] <- Gindx

  x <- Gao_s
  H <- x*x*c_coefft-b_coefft*x+a_coefft
  
  Gaoindx[thisYear,6] <- H
  # Do scoring of result with respect to resilience rating  
  GaoScore <- ifelse (Gao_s > s_ref, "A",(ifelse(Gao_H < H, "F", (ifelse(Gao_H < H_ref, "M", "A")))))

  Gaoindx[thisYear,7] <- GaoScore
}

# Get refrence line for the plot
x <- seq(0.01, 6.95, by=0.01) 
n <- length(x)
H <- x*x*c_coefft-b_coefft*x+a_coefft
gao_ref_pts <- data.frame(matrix(0, ncol = 2, nrow = n))
colnames(gao_ref_pts)[1:2] <- c("s","H")
gao_ref_pts$s <- x
gao_ref_pts$H <- H

ymin <- 1e-1
xmin <- 1e-2
ymax <- 1e+3
xmax <- 1e+3

# Plot the results as a scatter and line
outPlotName <- paste(OutDir,"/Gao_Index.png",sep="")
ggplot(data = Gaoindx, aes(x = Gao_s, y = Gao_H)) +
  geom_point(data = Gaoindx, size=1, aes(colour=rownames(Gaoindx))) + # Colour based on Year?
  geom_path(size = 0.2) + #so connected up through time (colour based on Year)
  geom_line(data = gao_ref_pts, aes(x = s, y = H)) + # refrence line details
  scale_x_log10(limits=c(xmin, xmax)) + scale_y_log10(limits=c(ymin, ymax)) +
  theme_bw() +
  labs(title = "Gao index", x = "<s>", y = "H", color='Year') +
  theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"),title=element_text(size=20,face="bold"))
ggsave(file=outPlotName)

# Plot the score through time
GaoindxPlot <- Gaoindx
GaoindxPlot <- subset (GaoindxPlot, select = -c(Gao_density, Gao_s, Gao_H, Gao_indx, resil_H))
GaoindxPlot$n <- 1
outPlotName <- paste(OutDir,"/Gao_Rating.png",sep="")
ggplot(data = GaoindxPlot, aes(x = Year, y = n, fill = GaoScore)) + geom_bar(colour = "black", stat="identity", size = 0.1) +
    scale_fill_manual(values = c("#00AFBB", "#E7B800", "#FC4E07")) + theme_bw() +
    labs(x="Years", y = "Gao Rating") +
    theme(axis.text=element_text(size=16,face="bold"), axis.title=element_text(size=20,face="bold"))
ggsave(file=outPlotName)

```

## Exploitation status- FSSI
Look at Blim (overfished) - so can use the calc step in the composite also do calc vs Btarg too composite index
Look at F vs Ftarg (overfishing)
Count of species in each state 

Index Scoring Methodology
Each quarter, NOAA Fisheries calculates an Fish Stock Sustainability Index score, incorporating information from new stock assessments and stock status determinations. The index is calculated on a 1,000 point scale using the following methodology:

Step 1: Assign weighted criteria points for each stock based on the following:

Criteria	Criteria Points
1. "Overfished" status is known.	0.5
2. "Overfishing" status is known.	0.5
3. Overfishing is not occurring (for stocks with known "overfishing" status).	1.0
4. Stock biomass is above the "overfished" level defined for the stock.	1.0
5. Stock biomass is at or above 80% of the biomass that produces maximum sustainable yield (BMSY) *	1.0
* Stocks rebuilding from a previously overfished condition are not awarded the fourth point until they reach Biomass Maximum Sustainable Yield, as mandated by the Magnuson-Stevens Act. After they have been fully rebuilt, they may fluctuate within the 80% parameter and retain the score of 4 like the other non-rebuilding stocks. This point is in addition to the point awarded for being above the “overfished” level.

Step 2: Calculate the sum of criteria points for all index stocks.

Step 3: Calculate maximum criteria points possible: multiply number of index stocks (175) x maximum criteria points per stock (4 points).

Step 4: Calculate a raw total point score: divide sum of criteria points / maximum criteria points possible.

Step 5: Convert raw total point score to a 1,000 point scale: total raw point score*1,000.

```{r}
# Reload reference biomasses - just in case
dftmp <- merge(df, dfRef, by=c("species_id")) # Intentional reuse
dftmp <- subset (dftmp, select = -c(Year.y, Year.x))
dfFSSI <- dftmp %>% dplyr::filter(IsDetritus == 0)
colnames(dfFSSI)[2] <- "Year"
dfFSSI$Rel_B <- dfFSSI$biomass_tonnes / dfFSSI$RefBo
dfFSSI$U<- dfFSSI$catch_tonnes / dfFSSI$biomass_tonnes
dfFSSI$Utarg <- 0.5 * dfFSSI$RefM
dfFSSI$Blim <- ifelse(dfFSSI$Class_Code < 7, 0.2, 0.4)
dfFSSI$Btarg <- ifelse(dfFSSI$Class_Code == 1, 0.4, 
                           (ifelse(dfFSSI$Class_Code == 2, 0.6, 
                                   (ifelse(dfFSSI$Class_Code == 3, 0.4, 
                                           (ifelse(dfFSSI$Class_Code == 4, 0.4, 
                                                   (ifelse(dfFSSI$Class_Code == 5, 0.48, 
                                                           (ifelse(dfFSSI$Class_Code == 6, 0.5, 0.7)))))))))))
dfFSSI$BtargB <- dfFSSI$Btarg * 0.8

dfFSSI$B_Score1 <- 0.5  # Needs to be replaced with meaningful value when used with observational data - right now assume status vs Blim, Btarg above is sufficient
dfFSSI$B_Score2 <- 0.5 # Needs to be replaced with meaningful value when used with observational data -- right now assume status vs U = 0.5M is sufficient test
dfFSSI$B_Score3 <- ifelse(dfFSSI$U < dfFSSI$Utarg, 1, 0)
dfFSSI$B_Score4 <- ifelse(dfFSSI$Rel_B > dfFSSI$Btarg, 1, 0)
dfFSSI$B_Score5 <- ifelse(dfFSSI$Rel_B > dfFSSI$BtargB, 1, 0)
dfFSSI$ScoreStatus <- ifelse(dfFSSI$Rel_B > dfFSSI$Btarg, "L", (ifelse(dfFSSI$Rel_B <= dfFSSI$Blim, "F", "A")))

  
# Assumes Thresholds
# 
#  CLass    ID    Blim  Btarg
#
# Vulnerable  1   0.2   0.4  
# Habitat     2   0.2   0.6
# Byproduct   3   0.2   0.4
# Bycatch     4   0.2   0.4
# Target      5   0.2   0.48
# Robust      6   0.2   0.5
# Hub         7   0.4   0.7
nSP <- length(unique(dfFSSI$Group))
MaxScore <- 4 * nSP
dfAggFSSI <- dfFSSI%>%
  group_by(Year) %>%
  dplyr::summarise(FSSI1 = sum(B_Score1), FSSI2 = sum(B_Score2), FSSI3 = sum(B_Score3), FSSI4 = sum(B_Score4), FSSI5 = sum(B_Score5))
dfAggFSSI$Total_FSSI <- dfAggFSSI$FSSI1 + dfAggFSSI$FSSI2 + dfAggFSSI$FSSI3 + dfAggFSSI$FSSI4 + dfAggFSSI$FSSI5
dfAggFSSI$Rel_FSSI <- dfAggFSSI$Total_FSSI / MaxScore
minFSSI <- round(min(dfAggFSSI$Rel_FSSI), digits = 2)
maxFSSI <- round(max(dfAggFSSI$Rel_FSSI), digits = 2)
notemsg <- paste("Minimum: ", minFSSI, " Maximum: ", maxFSSI, sep="")

plot_indx <- paste(OutDir,"/FSSI_indx.png",sep="")
ggplot(dfAggFSSI, aes (x = Year, y = Rel_FSSI), ) +
  geom_line(color = aggtscolor, size = 2) +
  theme(legend.position = "none")+
  expand_limits(y=0) +
  labs(
    title = "FFSI index - proportion of max possible score",
    subtitle = notemsg,
    x = "Year",
    y = "Relative FSSI"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)

```

# Composite
```{r}
#Possible results - A = Acceptable, F = Fail, L = Light
Score_Types <- c("F-F", "F-A", "A-F", "F-L", "L-F", "A-A", "A-L", "L-A", "L-L")
nScoreT <- length(Score_Types)
dfScore <- data.frame(matrix(0, ncol = 4, nrow = nScoreT))
colnames(dfScore)[1:4] <- c("CombinedScore","BaseScore","FiveCase","SixCase","SevenCase")
dfScore$CombinedScore <- Score_Types
dfScore$BaseScore <-c(0, 0.25, 0.375, 0.5, 0.75, 1.0, 1.5, 2.0, 2.5)
dfScore$FiveCase <-c(0, 0.675, 1.0125, 1.35, 2.025, 2.7, 4.05, 5.4, 6.75)
dfScore$SixCase <- c(0, 0.925, 1.3875, 1.85, 2.775, 3.7, 5.55, 7.4, 9.25)
dfScore$SevenCase <- c(0, 1.175, 1.7625, 2.35, 3.525, 4.7, 7.05, 9.4, 11.75)

# Class weighting
ClassTypes <- c("Vulnerable","Habitat","Byproduct","Bycatch","Target","Robust","Hub")
nClassT <- length(ClassTypes)
dfClassScore <- data.frame(matrix(0, ncol = 2, nrow = nClassT))
colnames(dfClassScore)[1:2] <- c("Classification","ClassScoreVal")
dfClassScore$Classification <- ClassTypes
dfClassScore$ClassScoreVal <- c(1, 1, 1, 0.1, 0.5, 0.1, 1)

# Construct dataframes
dfFSSIreuse <- dfFSSI
dfFSSIreuse <- subset (dfFSSIreuse, select = c(Year, species_id, Group, IsDetritus, Classification, ScoreStatus))
dfFSSIreuse <- dfFSSIreuse %>% dplyr::filter(IsDetritus < 1)

dfScoredreuse <- dfScored
dfScoredreuse <- subset (dfScoredreuse, select = c(Year, species_id, Group, Classification, DistortScore))

# Scores
dftmp <- merge(dfScoredreuse, dfFSSIreuse, by=c("Year","species_id","Group","Classification"))  # Intentional reuse
nThisClass <- length(unique(dftmp$Classification))
dfComp <- merge(dftmp, dfClassScore, by=c("Classification"))
dfComp$CombinedScore <- paste(dfComp$ScoreStatus,"-",dfComp$DistortScore, sep="")

# Classes
ClassList <- unique(dfComp$Classification)
nPerClass <- id2 %>% dplyr::count(Classification)

# Find the response bin
CHeckValID <- ifelse(nClassT == 7, 1, ifelse(nClassT == 6, 2, 3))
CHeckVal <- dfScore$FiveCase  # Set as default
if (CHeckValID ==1) {CHeckVal <- dfScore$SevenCase}
if (CHeckValID ==2) {CHeckVal <- dfScore$SixCase}

# Final score
minYear <- min(df$Year)
maxYear <- max(df$Year)
nYear <- maxYear - minYear + 1
dfCIndx <- data.frame(matrix(0, ncol = 3, nrow = nYear))
colnames(dfCIndx)[1:3] <- c("Year","BIndxBase","BIndx")

for (iYear in minYear:maxYear) {
  thisYear <- iYear - minYear + 1
  extractdf <- dfComp %>% dplyr::filter(Year == iYear)
  dftmp <- merge(extractdf, dfScore, by=c("CombinedScore"))  # Intentional reuse
  dftmp$FinalScore <- paste(dftmp$Classification,"-",dftmp$CombinedScore, sep="")
  
  nClassScores <- dftmp %>% 
    group_by(CombinedScore,Classification) %>%
    dplyr::summarise(ScoreStep1 = sum(ClassScoreVal))
  dftmp1 <- merge(nClassScores, dfClassScore, by=c("Classification")) # Intentional reuse
  dfCalc <- merge(dftmp1, nPerClass,  by=c("Classification"))
  dfCalc$WgtVal <- dfCalc$ScoreStep1 * dfCalc$ClassScoreVal / dfCalc$n
  
  dfGao <- Gaoindx %>% dplyr::filter(Year == iYear)
  GaoState <- dfGao$GaoScore
  resilWgt <- ifelse(GaoState == "A", 1.0, (ifelse(GaoState == "M", 0.8, 0.5)))
  ansScore <- sum(dfCalc$WgtVal) * resilWgt
  
  dfCIndx[thisYear,1] <- iYear
  dfCIndx[thisYear,2] <- ansScore
  
  if ( ansScore < CHeckVal[2]) {
    ansClass <- 1
  } else if ( ansScore < CHeckVal[3]) {
    ansClass <- 2
  } else if ( ansScore < CHeckVal[4]) {
    ansClass <- 3
  } else if ( ansScore < CHeckVal[5]) {
    ansClass <- 4
  } else if ( ansScore < CHeckVal[6]) {
    ansClass <- 5
  } else if ( ansScore < CHeckVal[7]) {
    ansClass <- 6
  } else if ( ansScore < CHeckVal[8]) {
    ansClass <- 7
  } else if ( ansScore < CHeckVal[9]) {
    ansClass <- 8
  } else {
    ansClass <- 9
  }
  dfCIndx[thisYear,3] <- ansClass
}  

# Create a column of colours
brewer.pal(10, "RdBu")
rbPal <- colorRampPalette(brewer.pal(10, "RdBu"))
dfCIndx$col <- rbPal(10)[as.numeric(cut(dfCIndx$BIndx,breaks = 10))]
dfCIndx$BIndx2 <- as.integer(dfCIndx$BIndx)

# Plot results
plot_indx <- paste(OutDir,"/BETHI_indx.png",sep="")
ggplot(dfCIndx, aes (x = Year, y = BIndx, colour=factor(BIndx2))) +
  geom_point(size = 2) + 
  scale_colour_brewer(palette = "RdYlGn") +
  expand_limits(y=0) + expand_limits(y=10) +
  labs(
    title = "Basic Ecosystem Traits & Health Index (BI)",
    x = "Year",
    y = "BI"
  ) + 
  theme(axis.text.y=element_text(size=10),axis.text.x=element_text(size=10), axis.title=element_text(size=12,face="bold"), strip.text = element_text(face="bold", size=10))
ggsave(file=plot_indx)


```

# Heatmaps - do last as screws up the plotting functions
```{r}
# Create a clean version of SP_as_col
CdataS <- df

# Replace spaces in names with "_"
CdataS$Group <- gsub("\\(", "", CdataS$Group)
CdataS$Group <- gsub("\\/", "", CdataS$Group)
CdataS$Group <- gsub(")", "", CdataS$Group)
CdataS$Group <- gsub("&", "", CdataS$Group)
CdataS$Group <- gsub("-", "", CdataS$Group)
CdataS$Group <- gsub(" ", "", CdataS$Group)
SP_as_colA <- reshape2::dcast(CdataS, Year ~ Group, value.var = "landings_tonnes")

# Replace NA with zeros
SP_as_colA[is.na(SP_as_colA)] <- 0

# Strip out columns of all zeros
SP_as_col <- SP_as_colA[, colSums(SP_as_colA != 0) > 0]

# Create row names and trim off first column
rownames(SP_as_col) <- SP_as_col[,1]
SP_as_col <- SP_as_col %>% dplyr::select(-Year)

# Transpose SP_as_col so years are column headers
# Here the va;ues are proportion of the catch but could be absolute catch
Yr_as_col <- t(SP_as_col)

#Replace NA with 0
Yr_as_col[is.na(Yr_as_col)] <- 0
Prop_Catch <- apply(Yr_as_col, 2, function(i) i/sum(i))

nSP <- length(Yr_as_col[,1])
nYr <- length(Yr_as_col[1,])

# Create new df to populate
drRanked <- data.frame(matrix(ncol = nYr, nrow = nSP))
colnames(drRanked)[1:nYr] = as.character(colnames(Yr_as_col)[1:nYr])
rownames(drRanked)[1:nSP] = as.character(rownames(Yr_as_col)[1:nSP])

# Do ranking (using order() routine as want largest value to be rated 1)
for (i in 1:nSP) {
  drRanked[i,] <- frank(Yr_as_col[i,], ties.method ="dense")
}

# Create the heatmap
HeatmapFilename <- paste("Landings heatmap.pdf",sep="") 
HeatmapTitle <- paste("Catch composition heatmap - catch data",sep="") 
heatmaply(drRanked,
          xlab = "Year",
          ylab = "Species",
          main = HeatmapTitle,
          dendrogram = "row",
          fontsize_col = 6,
          fontsize_row = 8,
          file = HeatmapFilename
)

HeatmapFilename <- paste("Proportion of landings heatmap.pdf",sep="") 
HeatmapTitle <- paste("Catch composition heatmap - proportion of catchh",sep="") 
heatmaply(Prop_Catch,
          xlab = "Year",
          ylab = "Species",
          main = HeatmapTitle,
          dendrogram = "row",
          fontsize_col = 6,
          fontsize_row = 8,
          file = HeatmapFilename
)

```


# Percentage of species area overlapping with fisheries  
This is not EwE model generated.

## Area of habitat effected by fishery  
(a) exploited  
(b) impacted (if not exploited directly)  
(c) protected  

This is not EwE model generated.
